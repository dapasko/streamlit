import streamlit as st
from openai import OpenAI
import io
from PyPDF2 import PdfReader
from PIL import Image
import mimetypes
import pandas as pd  # –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ CSV/JSON
import logging

# =========================
# Constants –∏ Logging
# =========================
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
MAX_HISTORY = 20  # –ú–∞–∫—Å–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è API (—Å —É—á—ë—Ç–æ–º summarization)
SUPPORTED_TYPES = ['.txt', '.pdf', '.jpg', '.png', '.csv', '.json', '.py']

# Logging –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (–Ω–µ –≤—ã–≤–æ–¥–∏—Ç –≤ UI, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =========================
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª–∏–µ–Ω—Ç–∞
# =========================
@st.cache_resource
def get_client():
    api_key = st.secrets.get("OPENROUTER_API_KEY")
    if not api_key:
        st.error("‚ùå API-–∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ secrets. –î–æ–±–∞–≤—å—Ç–µ OPENROUTER_API_KEY.")
        st.stop()
    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=api_key,
    )
    return client

client = get_client()

# =========================
# –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
# =========================
BASE_SYSTEM_PROMPT = {
    "role": "system",
    "content": """You are Sonoma, an experienced fullstack Python developer built by Oak AI. 
Your users are Russian-speaking clients who may come to you with any request: from coding help (Python, Streamlit, web dev, APIs, databases) to general advice, file analysis, or everyday questions. 
You know or can figure out answers to everything ‚Äî analyze problems logically, provide code snippets, step-by-step guides, and practical solutions. 
Always respond in Russian if the query is in Russian; otherwise, use English. Be friendly, helpful, witty, and use emojis where appropriate. 
Structure responses: use ```python for code blocks, bullet points or numbered lists for steps, bold for key points. 
If a file is uploaded, analyze it as developer: check for errors in code, suggest improvements, or summarize content. 
For images, since you are text-based, ask the user to describe it or suggest Python code to process it (e.g., with Pillow). 
Do not generate harmful content or role-play unless asked. You have session memory but no persistent storage."""
}

THINKING_MODE_PROMPT = "Before answering, think step by step: 1) Analyze the problem or request. 2) Outline the key steps or considerations. 3) Provide a clear, detailed solution or code. This ensures thorough and accurate responses."

# =========================
# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ (—É–ª—É—á—à–µ–Ω–Ω–∞—è —Å –∫—ç—à–µ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π)
# =========================
@st.cache_data
def process_file(uploaded_file):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: –≤–∞–ª–∏–¥–∞—Ü–∏—è, –ø–∞—Ä—Å–∏–Ω–≥, preview."""
    if uploaded_file.size > MAX_FILE_SIZE:
        return {"error": f"–§–∞–π–ª {uploaded_file.name} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({uploaded_file.size / 1024 / 1024:.1f} MB). –ú–∞–∫—Å–∏–º—É–º: 10MB."}

    file_extension = mimetypes.guess_extension(uploaded_file.type) or ''
    if file_extension not in SUPPORTED_TYPES:
        return {"error": f"–¢–∏–ø —Ñ–∞–π–ª–∞ {file_extension} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –ü–æ–¥–¥–µ—Ä–∂–∫–∞: {', '.join(SUPPORTED_TYPES)}"}

    uploaded_file.seek(0)  # –°–±—Ä–æ—Å –ø–æ–∑–∏—Ü–∏–∏ –≤ –ø–æ—Ç–æ–∫–µ
    progress_bar = st.progress(0)

    try:
        if file_extension.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp']:
            image = Image.open(uploaded_file)
            st.image(image, caption=uploaded_file.name, width=200)
            preview = f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ '{uploaded_file.name}' (—Ä–∞–∑–º–µ—Ä: {uploaded_file.size} –±–∞–π—Ç). –û–ø–∏—à–∏ –µ–≥–æ, –∏ —è –ø–æ–º–æ–≥—É —Å Python-–∫–æ–¥–æ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, Pillow)."
            content = preview  # –î–ª—è –ø—Ä–æ–º–ø—Ç–∞
            file_type = "image"
            progress_bar.progress(1)

        elif file_extension.lower() == '.pdf':
            pdf_bytes = uploaded_file.read()
            reader = PdfReader(io.BytesIO(pdf_bytes))
            text = ""
            num_pages = len(reader.pages)
            for i, page in enumerate(reader.pages):
                text += page.extract_text() + "\n"
                progress_bar.progress((i + 1) / num_pages)
            preview = text[:1000] + "..." if len(text) > 1000 else text
            content = text[:4000] + "..." if len(text) > 4000 else text
            file_type = "pdf"

        elif file_extension.lower() in ['.csv']:
            df = pd.read_csv(uploaded_file)
            st.dataframe(df.head(10), use_container_width=True)  # Preview —Ç–∞–±–ª–∏—Ü—ã
            preview = df.head(5).to_string(index=False) + "..." if len(df) > 5 else df.to_string(index=False)
            content = df.to_json(orient='records')  # –ü–æ–ª–Ω—ã–π JSON –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
            file_type = "csv"
            progress_bar.progress(1)

        elif file_extension.lower() == '.json':
            json_data = pd.read_json(uploaded_file)
            st.json(json_data.head().to_dict())  # Preview JSON
            preview = str(json_data.head().to_dict())[:500] + "..."
            content = uploaded_file.getvalue().decode("utf-8")
            file_type = "json"
            progress_bar.progress(1)

        else:  # .txt, .py, .md –∏ —Ç.–¥.
            text = uploaded_file.read().decode("utf-8", errors="ignore")
            preview = text[:500] + "..." if len(text) > 500 else text
            content = text[:4000] + "..." if len(text) > 4000 else text
            file_type = "text"
            progress_bar.progress(1)

        return {"type": file_type, "preview": preview, "content": content, "no_error": True}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {uploaded_file.name}: {e}")
        return {"error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"}

# =========================
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π (—Å summarization –¥–ª—è –¥–ª–∏–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏)
# =========================
def build_messages(system_prompt, session_messages):
    """–°–±–æ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è API. –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è –¥–ª–∏–Ω–Ω–∞—è ‚Äî summarization —Å—Ç–∞—Ä–æ–π —á–∞—Å—Ç–∏."""
    api_messages = [system_prompt]

    if len(session_messages) > MAX_HISTORY + 1:
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Å—Ç–∞—Ä—É—é –∏ –Ω–æ–≤—É—é –∏—Å—Ç–æ—Ä–∏—é
        old_limit = MAX_HISTORY // 2
        old_msgs = [{"role": msg["role"], "content": msg["content"] if isinstance(msg["content"], str) else " ".join([part["text"] for part in msg["content"]])} for msg in session_messages[1:1 + old_limit]]

        try:
            # Summarization —Å—Ç–∞—Ä–æ–π –∏—Å—Ç–æ—Ä–∏–∏
            summary_prompt = {"role": "system", "content": "–°—É–º–º–∞—Ä–∏–∑—É–π –ø—Ä–µ–¥—ã–¥—É—â—É—é –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∫—Ä–∞—Ç–∫–æ (1-2 –∞–±–∑–∞—Ü–∞), —Å–æ—Ö—Ä–∞–Ω—è—è –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."}
            summary_completion = client.chat.completions.create(
                model=st.session_state.get("model", "openrouter/sonoma-sky-alpha"),
                messages=[summary_prompt] + old_msgs,
                max_tokens=500,
                temperature=0.3
            )
            summary = summary_completion.choices[0].message.content
            api_messages.append({"role": "system", "content": f"–ü—Ä–µ–¥—ã–¥—É—â–∞—è –∏—Å—Ç–æ—Ä–∏—è (–∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä): {summary}"})

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–¥–∞–≤–Ω–∏–µ
            recent_msgs = session_messages[1 + old_limit:]
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ summarization: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –æ–±—Ä–µ–∑–∫—É.")
            recent_msgs = session_messages[-(MAX_HISTORY // 2):]
    else:
        recent_msgs = session_messages

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–∞–≤–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    for msg in recent_msgs:
        if msg["role"] in ["user", "assistant"]:
            if isinstance(msg["content"], str):
                api_messages.append({"role": msg["role"], "content": msg["content"]})
            else:  # –§–∞–π–ª–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                text_content = " ".join([part["text"] for part in msg["content"] if isinstance(part, dict) and part.get("type") == "text"])
                api_messages.append({"role": msg["role"], "content": text_content})

    return api_messages

# =========================
# –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
# =========================
def generate_response(api_messages, model, temperature):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫."""
    try:
        with st.spinner("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç..."):
            completion = client.chat.completions.create(
                model=model,
                messages=api_messages,
                temperature=temperature,
                max_tokens=3000,
            )
        return completion.choices[0].message.content
    except Exception as e:
        logger.error(f"API –æ—à–∏–±–∫–∞: {e}")
        if "rate limit" in str(e).lower():
            return "‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ API-–∫–ª—é—á."
        elif "invalid" in str(e).lower():
            return "‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω—ã–π API-–∫–ª—é—á –∏–ª–∏ –º–æ–¥–µ–ª—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
        else:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API: {str(e)}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å."

# =========================
# –§—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —á–∞—Ç–∞
# =========================
def export_chat(messages):
    """–≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ –≤ TXT."""
    if len(messages) <= 1:
        st.warning("–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞.")
        return

    output = io.StringIO()
    for msg in messages[1:]:
        if msg["role"] not in ["user", "assistant"]:
            continue
        if isinstance(msg["content"], str):
            content_str = msg["content"]
        else:
            if "preview" in msg:
                content_str = f"[–§–∞–π–ª: {msg['name']} ({msg.get('file_type', 'unknown')})] {msg['preview']}"
            else:
                content_str = str(msg["content"])[:200] + "..."
        output.write(f"{msg['role'].title()}: {content_str}\n\n")

    st.download_button(
        label="üì• –°–∫–∞—á–∞—Ç—å —á–∞—Ç –∫–∞–∫ TXT",
        data=output.getvalue(),
        file_name="sonoma_chat.txt",
        mime="text/plain"
    )

# =========================
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# =========================
st.set_page_config(
    page_title="ü§ñ Sonoma ‚Äî Fullstack Python Dev",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)
st.title("ü§ñ Sonoma –æ—Ç Oak AI: –¢–≤–æ–π Fullstack Python –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫")
st.markdown("---")
st.caption("–ü—Ä–∏–≤–µ—Ç! –Ø Sonoma, –æ–ø—ã—Ç–Ω—ã–π fullstack Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫. –û–±—Ä–∞—â–∞–π—Å—è —Å –ª—é–±–æ–π –ø—Ä–æ—Å—å–±–æ–π ‚Äî –æ—Ç –∫–æ–¥–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–æ–≤ –¥–æ —Å–æ–≤–µ—Ç–æ–≤. –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã? –û—Ç–≤–µ—á–∞—é –Ω–∞ —Ä—É—Å—Å–∫–æ–º! üòä")

# =========================
# Sidebar
# =========================
with st.sidebar:
    st.header("‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
    thinking_mode = st.checkbox("üß† –†–µ–∂–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –æ–±–¥—É–º—ã–≤–∞–Ω–∏—è", value=False)
    st.session_state.model = st.selectbox("ü§ñ –ú–æ–¥–µ–ª—å", ["openrouter/sonoma-sky-alpha"], key="model_select")  # –†–∞—Å—à–∏—Ä—è–µ–º–æ
    temperature = st.slider("üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (–∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å)", 0.0, 1.0, 0.7 if not thinking_mode else 0.3)

    st.subheader